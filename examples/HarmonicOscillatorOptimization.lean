import SciLean

open SciLean

set_default_scalar Float

def H (m k : Float) (x p : Float) := (1/(2*m)) * p^2 + k/2 * x^2

variable (f : â„Ã—â„Ã—â„• â†’ â„)

variable (x y : â„Ã—â„)

#check Function.not_lt_argmin

#check Function.argmin f

open Lean Parser Term in
macro "argmin" xs:funBinder* ", " b:term : term => do
  `(Function.argmin â†¿fun $xs* => $b)


theorem solve_eq_argmin_norm2
    (R : Type*) [RealScalar R]
    {X : Type*} [NormedAddCommGroup X] [AdjointSpace R X] [CompleteSpace X]
    {Y : Type*} [NormedAddCommGroup Y] [AdjointSpace R Y] [CompleteSpace Y]
    {f : X â†’ Y} {y : Y} (hf : HasUniqueSolution (fun x => f x = y)) :
    (solve x, f x = y) = argmin x, â€–f x - yâ€–â‚‚Â²[R] := sorry_proof


theorem revFDeriv_eq_fwdFDeriv
    {R : Type*} [RealScalar R]
    {f : R â†’ R} :
    (revFDeriv R f)
    =
    fun x =>
      let' (y,dy) := fwdFDeriv R f x 1
      (y, fun dy' => dy*dy') := by sorry_proof



open Optimjl

-- not sure how to define this yet
opaque Options.filter {R : Type} [RealScalar R] : Filter (Options R) := default

theorem argmin_eq_limit_optimize
    {R : Type} [RealScalar R]
    {X : Type} [NormedAddCommGroup X] [AdjointSpace R X] [CompleteSpace X]
    {Method : Type*} {State : outParam Type} [AbstractOptimizer Method State R X]
    (method : Method) (xâ‚€ : X)
    {f : X â†’ R} :
    (argmin x, f x)
    =
    limit opts âˆˆ Options.filter (R:=R),
      let f' := holdLet <| revFDeriv R f
      let r := optimize' {f:=f,f':=f',hf:=sorry_proof} (AbstractOptimizer.setOptions X method opts) xâ‚€
      r.minimizer := sorry_proof


@[fun_prop]
theorem holdLet.arg_a.Differentiable_rule
  {ğ•œ} [RCLike ğ•œ] {X} [NormedAddCommGroup X] [NormedSpace ğ•œ X] :
  IsContinuousLinearMap ğ•œ fun x : X => holdLet x := by simp[holdLet]; fun_prop

@[fun_prop]
theorem holdLet.arg_a1.Differentiable_rule
  {ğ•œ} [RCLike ğ•œ]
  {X} [NormedAddCommGroup X] [NormedSpace ğ•œ X]
  {Y} [NormedAddCommGroup Y] [NormedSpace ğ•œ Y]
  (f : X â†’ Y) (hf : Differentiable ğ•œ f):
  Differentiable ğ•œ (holdLet f) := by simp[holdLet,hf]

@[fun_prop]
theorem holdLet.arg_a1.IsContinusousLinearMap_rule
  {ğ•œ} [RCLike ğ•œ]
  {X} [NormedAddCommGroup X] [NormedSpace ğ•œ X]
  {Y} [NormedAddCommGroup Y] [NormedSpace ğ•œ Y]
  (f : X â†’ Y) (hf : IsContinuousLinearMap ğ•œ f):
  IsContinuousLinearMap ğ•œ (holdLet f) := by simp[holdLet,hf]

@[fun_trans]
theorem holdLet.arg_a1.fwdFDeriv_rule
  {ğ•œ} [RCLike ğ•œ]
  {X} [NormedAddCommGroup X] [NormedSpace ğ•œ X]
  {Y} [NormedAddCommGroup Y] [NormedSpace ğ•œ Y]
  (f : X â†’ Y) :
  fwdFDeriv ğ•œ (holdLet f) = holdLet (fwdFDeriv ğ•œ f) := by rfl

@[simp, simp_core]
theorem holdLet_apply {Î± Î² : Type*} (f : Î± â†’ Î²) (x : Î±) : holdLet f x = f x := rfl

approx solver (m T X kâ‚€ : Float) :=
  let y := holdLet <| fun (k : Float) =>
    odeSolve (tâ‚€ := 0) (t:=T) (xâ‚€:=(X,0))
      (fun (t : Float) (x,p) =>
        ( âˆ‡ (p':=p), H m k x  p',
         -âˆ‡ (x':=x), H m k x' p))
  solve k, (y k).1 = X
by
  conv =>
    -- focus on the specification
    enter[2]

    -- Unfold Hamiltonian and compute gradients
    unfold H; autodiff

    conv =>
      -- focus on solve k, (y k).1 = X
      enter[y]

      -- reformulate as minimization problem
      rw[solve_eq_argmin_norm2 Float (by sorry_proof)]

      -- approximate by gradient descrent
      rw[argmin_eq_limit_optimize (R:=Float)
          (xâ‚€ := kâ‚€)
          (method := (default : LBFGS Float 1))]

  -- consume limit by `Approx`
  -- approx limit is not respecting leading let binding!
  -- I thing this is because of the final apply `Approx.limit _ _`
  approx_limit opts sorry_proof

  conv =>
    -- focus on the specification again
    enter[2]

    -- rewrite reverse mode AD (<âˆ‚) as forward mode AD (âˆ‚>)
    -- this is possible because we are differentiating scalar function `Float â†’ Float`
    simp -zeta only [revFDeriv_eq_fwdFDeriv]

    -- run forward mode AD
    -- this will formulate a new ODE that solves for `x`, `p`, `dx/dk` and `dp/dk`
    autodiff

  -- approximate both ODEs with RK4
  simp -zeta only [odeSolve_fixed_dt rungeKutta4 sorry_proof]

  -- choose the same number of steps for both ODE solvers
  -- and consume the corresponding limin in `Approx`
  approx_limit steps sorry_proof


#check Nat



#eval solver (m:=1) (T:=1) (X:=1) (kâ‚€:=60) ({g_abstol := 1e-15, init_alpha := 10, show_trace := true},200,())



#exit

open Scalar

set_default_scalar Float


set_option trace.Meta.Tactic.fun_trans true in
#check
  (let f := holdLet (exp : Float â†’ Float)
   (âˆ‚> f 0)) rewrite_by lfun_trans -zeta
