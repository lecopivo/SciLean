import SciLean

import SciLean.Core.Distribution.Basic
import SciLean.Core.Distribution.ParametricDistribDeriv
import SciLean.Core.Distribution.ParametricDistribFwdDeriv
import SciLean.Core.Distribution.ParametricDistribRevDeriv

import SciLean.Core.Functions.Gaussian

namespace SciLean

open Rand MeasureTheory

variable {R} [RealScalar R] [MeasureSpace R]

set_default_scalar R


----------------------------------------------------------------------------------------------------
-- Variational Inference - Test 1 ------------------------------------------------------------------
----------------------------------------------------------------------------------------------------

def model1 :=
  let v ~ normal (0:R) 5
  if v > 0 then
    let obs ~ normal (1:R) 1
  else
    let obs ~ normal (-2:R) 1


def guide1 (Î¸ : R) := normal Î¸ 1


noncomputable
def loss1 (Î¸ : R) := KLDiv (R:=R) (guide1 Î¸) (model1.conditionSnd 0)


variable
  {W} [Vec R W]
  {X} [MeasurableSpace X] [Vec R X]
  {Y} [Vec R Y] [Module â„ Y]

@[fun_trans]
theorem Rand.ð”¼.arg_r.cderiv_rule (r : W â†’ Rand X) (f : X â†’ Y) :
  cderiv R (fun w => (r w).ð”¼ f)
  =
  fun w dw =>
    let d := parDistribDeriv (fun w => (r w).â„™.toDistribution (R:=R)) w dw
    d.extAction f (fun r âŠ¸ fun y âŠ¸ ((r â€¢ y) : Y)) := sorry_proof


#check parDistribFwdDeriv

@[fun_trans]
theorem Rand.ð”¼.arg_r.cderiv_rule' (r : W â†’ Rand X) (f : W â†’ X â†’ Y)
  (hf : âˆ€ x, CDifferentiable R (f Â· x)) :
  cderiv R (fun w => (r w).ð”¼ (f w))
  =
  fun w dw =>
    let dr := parDistribFwdDeriv (fun w => (r w).â„™.toDistribution (R:=R)) w dw
    let df := fun x => fwdDeriv R (f Â· x) w dw
    dr.extAction df (fun rdr âŠ¸ fun ydy âŠ¸ rdr.1â€¢ydy.2 + rdr.2â€¢ydy.1) := sorry_proof



section hihi

variable
  {X : Type _} [SemiInnerProductSpace R X] [MeasurableSpace X]
  {W : Type _} [SemiInnerProductSpace R W]
  {Y : Type _} [SemiInnerProductSpace R Y] [Module â„ Y]
  {U} [SemiHilbert R U] [MeasureSpace U]

noncomputable
def normalFDÎ¼ (Î¼ : U) (Ïƒ : R) : ð’Ÿ'(U,RÃ—R) :=
  âŸ¨fun Ï† => (âˆ«' x, Ï† x * gaussian Î¼ Ïƒ x, âˆ«' x, Ï† x * ), sorry_proofâŸ©


@[fun_trans]
theorem Rand.ð”¼.arg_r.revDeriv_rule' (r : W â†’ Rand X) (f : W â†’ X â†’ Y)
  (hf : âˆ€ x, HasAdjDiff R (f Â· x)) :
  revDeriv R (fun w => (r w).ð”¼ (f w))
  =
  fun w =>
    let dr := parDistribRevDeriv (fun w => (r w).â„™.toDistribution (R:=R)) w
    let df := fun x => revDeriv' R (f Â· x) w
    dr.extAction df âŸ¨fun rdr => âŸ¨fun ydf => (rdr.1â€¢ydf.1, fun dy => ydf.2 (rdr.1â€¢dy) + rdr.2 âŸªydf.1,dyâŸ«),sorry_proofâŸ©,sorry_proofâŸ© := sorry_proof

end hihi


set_option trace.Meta.Tactic.simp.rewrite true in
/-- Compute derivative of `loss1` by directly differentiating KLDivergence -/
def loss1_deriv := (âˆ‚ Î¸ : R, loss1 Î¸) rewrite_by
  unfold loss1
  unfold scalarCDeriv
  simp only [kldiv_elbo]  -- log P(X) - ELBO P(Z,X) Q(Z)
  autodiff
  unfold model1 guide1 ELBO
  simp (config:={zeta:=false}) only [ftrans_simp,Scalar.log_mul, Tactic.lift_lets_simproc]
  autodiff

#check SciLean.norm2_scalar

#check gaussian

#check normal (0:Float) 1

#check (normal 0.0 1.0).â„™
#eval  (normal 0.0 1.0).get

#check Rand
